{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45fc9086-93aa-4645-8ba2-380c3acbbed9",
   "metadata": {},
   "source": [
    "# Level 3: Agentic RAG with reference Eval\n",
    "\n",
    "This tutorial presents an example of evaluating an agentic RAG in LLama-Stack using the reference implementation. \n",
    "Please refer to the [Level 3: Agentic RAG](./Level3_agentic_RAG.ipynb) notebook for details on how to initialize the agent and the knowledge search RAG tool provided by Llama Stack.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers the following steps:\n",
    "1. Connecting to a llama-stack server.\n",
    "2. Indexing a collection of documents in a vector DB for later retrieval.\n",
    "3. Initializing the agent capable of retrieving content from vector DB via tool use.\n",
    "4. Evaluating the agent responses against a reference set of Q&A.\n",
    "5. Reporting the evaluation results and its statistical relevance.\n",
    "\n",
    "## Case study\n",
    "For the purpose of this training, we are going to use the fictional company \n",
    "[Parasol Financial](https://www.redhat.com/en/blog/ai-insurance-industry-insights-red-hat-summit-2024), and the provided\n",
    "[training documents](https://github.com/jharmison-redhat/parasol-financial-data/).\n",
    "\n",
    "A sample Q&A document is available as a [reference](./data/parasol-financial-data_qac.yaml). \n",
    "This predefined question and answer pairs have beeen generated using [docling-sdg](https://github.com/docling-project/docling-sdg),\n",
    "an IBM set of tools to create artificial data from documents, leveraging generative AI and Docling's parsing capabilities.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting, ensure you have a running instance of the Llama Stack server (local or remote) with at least one preconfigured vector DB. For more information, please refer to the corresponding [Llama Stack tutorials](https://llama-stack.readthedocs.io/en/latest/getting_started/index.html).\n",
    "\n",
    "The `openai` inference provider is required if you intend to use an OpenAI model for judging purposes, like `openai/gpt-4o`. In this case, the \n",
    "`OPENAI_API_KEY` env variable must be configured into the Llama Stack server.\n",
    "\n",
    "## Setting the Environment Variables\n",
    "\n",
    "Use the [`.env.example`](../../../.env.example) to create a new file called `.env` and ensure you add all the relevant environment variables below.\n",
    "\n",
    "In addition to the environment variables listed in the [\"Getting Started\" notebook](demos/rag_agentic/notebooks/Level0_getting_started_with_Llama_Stack.ipynb), the following should be provided for this demo to run:\n",
    " - `LLM_AS_JUDGE_MODEL_ID`: the model to use as the judge to evaluate the agent responses. Must be one of the models defined in Llama Stack.\n",
    " - `VDB_PROVIDER`: the vector DB provider to be used. Must be supported by Llama Stack. For this demo, we use Milvus Lite which is our preferred solution.\n",
    " - `VDB_EMBEDDING`: the embedding model to be used for ingestion and retrieval. For this demo, we use all-MiniLM-L6-v2.\n",
    " - `VDB_EMBEDDING_DIMENSION` (optional): the dimension of the embedding. Defaults to 384.\n",
    " - `VECTOR_DB_CHUNK_SIZE` (optional): the chunk size for the vector DB. Defaults to 512."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db34e4b-ed29-4007-b760-59543d4caca1",
   "metadata": {},
   "source": [
    "## 1. Setting Up the Environment\n",
    "We will start with a few imports needed for this demo only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854e7cb4-aed9-4098-adc1-a66f4c9e6ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "from rich.pretty import pprint\n",
    "\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "from llama_stack_client import Agent, AgentEventLogger, RAGDocument\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab4244-e7af-405b-b0c3-4bf00411f26e",
   "metadata": {},
   "source": [
    "Next, we will initialize our environment as described in detail in our [\"Getting Started\" notebook](demos/rag_agentic/notebooks/Level0_getting_started_with_Llama_Stack.ipynb). Please refer to it for additional explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b87b139-bd18-47b2-889a-1b8ed3018655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server @ http://localhost:8321\n",
      "Inference Parameters:\n",
      "\tModel: granite32-8b\n",
      "\tSampling Parameters: {'strategy': {'type': 'greedy'}, 'max_tokens': 4096}\n",
      "\tstream: True\n",
      "Eval Parameters:\n",
      "\tJudge Model: openai/gpt-4o\n",
      "\tQ&A file: ./data/parasol-financial-data_qac.yaml\n",
      "\tMax rows: 50\n"
     ]
    }
   ],
   "source": [
    "# for accessing the environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# for communication with Llama Stack\n",
    "from llama_stack_client import LlamaStackClient\n",
    "# to override the judge model\n",
    "from llama_stack.providers.inline.scoring.llm_as_judge.scoring_fn.fn_defs.llm_as_judge_405b_simpleqa import (\n",
    "    llm_as_judge_405b_simpleqa,\n",
    ")\n",
    "\n",
    "# pretty print of the results returned from the model/agent\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from src.utils import step_printer\n",
    "from termcolor import cprint\n",
    "\n",
    "remote = os.getenv(\"REMOTE\", \"True\")\n",
    "\n",
    "if remote == \"False\":\n",
    "    local_port = os.getenv(\"LOCAL_SERVER_PORT\", 8321)\n",
    "    base_url = f\"http://localhost:{local_port}\"\n",
    "else: # any value non equal to 'False' will be considered as 'True'\n",
    "    base_url = os.getenv(\"REMOTE_BASE_URL\")\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url,\n",
    "    provider_data=None\n",
    ")\n",
    "    \n",
    "print(f\"Connected to Llama Stack server @ {base_url}\")\n",
    "\n",
    "# model_id will later be used to pass the name of the desired inference model to Llama Stack Agents/Inference APIs\n",
    "model_id = os.getenv(\"INFERENCE_MODEL_ID\")\n",
    "\n",
    "temperature = float(os.getenv(\"TEMPERATURE\", 0.0))\n",
    "if temperature > 0.0:\n",
    "    top_p = float(os.getenv(\"TOP_P\", 0.95))\n",
    "    strategy = {\"type\": \"top_p\", \"temperature\": temperature, \"top_p\": top_p}\n",
    "else:\n",
    "    strategy = {\"type\": \"greedy\"}\n",
    "\n",
    "max_tokens = int(os.getenv(\"MAX_TOKENS\", 4096))\n",
    "\n",
    "# sampling_params will later be used to pass the parameters to Llama Stack Agents/Inference APIs\n",
    "sampling_params = {\n",
    "    \"strategy\": strategy,\n",
    "    \"max_tokens\": max_tokens,\n",
    "}\n",
    "\n",
    "stream_env = os.getenv(\"STREAM\", \"True\")\n",
    "# the Boolean 'stream' parameter will later be passed to Llama Stack Agents/Inference APIs\n",
    "# any value non equal to 'False' will be considered as 'True'\n",
    "stream = (stream_env != \"False\")\n",
    "\n",
    "# The Q&A file\n",
    "QNA_FILE = './data/parasol-financial-data_qac.yaml'\n",
    "# The number of rows to consider\n",
    "MAX_QNA_ROWS = 50\n",
    "# Set to True to enable display of evaluation results\n",
    "EVAL_DEBUG = False\n",
    "llm_as_judge_model = os.getenv(\"LLM_AS_JUDGE_MODEL_ID\")\n",
    "llm_as_judge_405b_simpleqa_params = llm_as_judge_405b_simpleqa.params.model_copy()\n",
    "# Override the default model\n",
    "# To update the scoring params, we need to provide all the settings, including the defaults\n",
    "llm_as_judge_405b_simpleqa_params.judge_model = llm_as_judge_model\n",
    "\n",
    "# Convert the model dump to a dictionary\n",
    "scoring_params = llm_as_judge_405b_simpleqa_params.model_dump()\n",
    "scoring_params['aggregation_functions']=['categorical_count']\n",
    "\n",
    "print(f\"Inference Parameters:\\n\\tModel: {model_id}\\n\\tSampling Parameters: {sampling_params}\\n\\tstream: {stream}\")\n",
    "print(f\"Eval Parameters:\\n\\tJudge Model: {llm_as_judge_model}\\n\\tQ&A file: {QNA_FILE}\\n\\tMax rows: {MAX_QNA_ROWS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357655b5-cade-46f4-9f57-be5dcef9abc2",
   "metadata": {},
   "source": [
    "Finally, we will initialize the document collection to be used for RAG ingestion and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583421f3-5c77-4964-b525-12f967c20816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Registered vector DB **test_vector_db_9f241a68-0d86-4123-9ade-5a3329963983**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_db_id = f\"test_vector_db_{uuid.uuid4()}\"\n",
    "display_markdown(f\"Registered vector DB **{vector_db_id}**\", raw=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9203de51-f570-44ab-8130-36333a54888b",
   "metadata": {},
   "source": [
    "## 2. Indexing the Documents\n",
    "- Initialize a new document collection in the target vector DB. All parameters related to the vector DB, such as the embedding model and dimension, must be specified here.\n",
    "- Provide a list of document URLs to the RAG tool. Llama Stack will handle fetching, conversion and chunking of the documents' content.\n",
    "- Perform a sample query to verify the response is retrieved from the relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd4664a-ff7f-4474-b6af-3a4ad3f73052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define and register the document collection to be used\n",
    "client.vector_dbs.register(\n",
    "    vector_db_id=vector_db_id,\n",
    "    embedding_model=os.getenv(\"VDB_EMBEDDING\"),\n",
    "    embedding_dimension=int(os.getenv(\"VDB_EMBEDDING_DIMENSION\", 384)),\n",
    "    provider_id=os.getenv(\"VDB_PROVIDER\"),\n",
    ")\n",
    "\n",
    "# ingest the documents into the newly created document collection\n",
    "urls = [\n",
    "    \"flexible_enhanced_checking/flexible_enhanced_checking.md\",\n",
    "    \"flexible_savings/flexible_savings.md\",\n",
    "    \"flexible_premier_checking/flexible_premier_checking.md\",\n",
    "    \"flexible_core_checking/flexible_core_checking.md\",\n",
    "    \"policies/online_service_agreement.md\",\n",
    "    \"enablement/customer_interactions_resource_guide.md\",\n",
    "    \"enablement/banking_essentials_resource_guide.md\",\n",
    "    \"flexible_money_market_savings/flexible_money_market_savings.md\",\n",
    "    \"flexible_checking/flexible_checking.md\",\n",
    "]\n",
    "documents = [\n",
    "    RAGDocument(\n",
    "        document_id=f\"{url.split('/')[-1]}\",\n",
    "        content=f\"https://raw.githubusercontent.com/jharmison-redhat/parasol-financial-data/main/{url}\",\n",
    "        mime_type=\"text/plain\",\n",
    "        metadata={},\n",
    "    )\n",
    "    for i, url in enumerate(urls)\n",
    "]\n",
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=documents,\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=int(os.getenv(\"VECTOR_DB_CHUNK_SIZE\", 512)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2ee986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flexible_money_market_savings.md',\n",
       " 'flexible_money_market_savings.md',\n",
       " 'flexible_savings.md',\n",
       " 'flexible_savings.md',\n",
       " 'online_service_agreement.md']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query documents\n",
    "results = client.tool_runtime.rag_tool.query(\n",
    "    vector_db_ids=[vector_db_id],\n",
    "    content=\"What is the Parasol Financial Withdrawal Limit Fee and Transaction Limitations for Flexible Money Market Savings\",\n",
    ")\n",
    "results.metadata['document_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99392db2",
   "metadata": {},
   "source": [
    "## 3. Defining reusable functions\n",
    "Define reusable Python functions to use during the execution of the evaluation jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9c3b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_from_categorical_count(response):\n",
    "    \"\"\"\n",
    "    Computes the evaluation accuracy from the responses of the `llm-as-judge::405b-simpleqa`\n",
    "    scoring function.\n",
    "\n",
    "    Expected responses are:\n",
    "    ```\n",
    "    A: CORRECT\n",
    "    B: INCORRECT\n",
    "    C: NOT_ATTEMPTED\n",
    "    ```\n",
    "    The accuracy is computed as: <number of responses of type `A`> / <number of responses> * 100\n",
    "    \"\"\"\n",
    "    # Evaluate numerical score\n",
    "    correct_answers = sum(\n",
    "        [\n",
    "            count\n",
    "            for cat, count in response.scores[\"llm-as-judge::405b-simpleqa\"]\n",
    "            .aggregated_results[\"categorical_count\"][\"categorical_count\"]\n",
    "            .items()\n",
    "            if cat == \"A\"\n",
    "        ]\n",
    "    )\n",
    "    num_of_scores = len(response.scores[\"llm-as-judge::405b-simpleqa\"].score_rows)\n",
    "    return correct_answers / num_of_scores * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb981c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_eval(use_rag: bool):\n",
    "    \"\"\"\n",
    "    Runs the evaluation function for the benchmark indicated by the global variable `qna_benchmark_id`.\n",
    "    A new agent is created for every function call: in case `use_rag` is set to `True`, the `knowledge_search` tool is defined\n",
    "    to implement the RAG workflow.\n",
    "    The global variables `model_id` and `vector_db_id` are also requested.\n",
    "\n",
    "    Params:\n",
    "        use_rag: whether to run a RAG workflow or not.\n",
    "    Returns:\n",
    "        the `Job` associated to the evaluation function.\n",
    "    \"\"\"\n",
    "\n",
    "    from httpx import Timeout\n",
    "\n",
    "    if use_rag == True:\n",
    "        instructions = \"You are a helpful assistant. You must use the knowledge search tool to answer user questions.\"\n",
    "        tools = [\n",
    "            dict(\n",
    "                name=\"builtin::rag/knowledge_search\",\n",
    "                args={\n",
    "                    \"vector_db_ids\": [\n",
    "                        vector_db_id\n",
    "                    ],  # list of IDs of document collections to consider during retrieval\n",
    "                },\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        instructions = \"You are a helpful assistant.\"\n",
    "        tools = []\n",
    "\n",
    "    agent_config = {\n",
    "        \"model\": model_id,\n",
    "        \"instructions\": instructions,\n",
    "        \"sampling_params\": sampling_params,\n",
    "        \"toolgroups\": tools,\n",
    "    }\n",
    "\n",
    "    _job = client.eval.run_eval(\n",
    "        benchmark_id=qna_benchmark_id,\n",
    "        benchmark_config={\n",
    "            \"num_examples\": MAX_QNA_ROWS,\n",
    "            \"scoring_params\": {\n",
    "                \"llm-as-judge::405b-simpleqa\": scoring_params,\n",
    "            },\n",
    "            \"eval_candidate\": {\n",
    "                \"type\": \"agent\",\n",
    "                \"config\": agent_config,\n",
    "            },\n",
    "        },\n",
    "        timeout=Timeout(MAX_QNA_ROWS * 30),  # Allow for 30s per Q&A\n",
    "    )\n",
    "    return _job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d406ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_eval_reponse(_job):\n",
    "    \"\"\"\n",
    "    Returns the `EvalResponse` instance for the given `_job`.\n",
    "\n",
    "    Params:\n",
    "        `job_id`: The evaluation `Job`.\n",
    "    Returns:\n",
    "        The `EvalResponse` for the given `_job`\n",
    "    \"\"\"\n",
    "    status = client.eval.jobs.status(\n",
    "        benchmark_id=qna_benchmark_id, job_id=_job.job_id\n",
    "    ).status\n",
    "    while status != \"completed\":\n",
    "        print(f\"Job status is {status}\")\n",
    "        sleep(1)\n",
    "        status = client.eval.jobs.status(\n",
    "            benchmark_id=qna_benchmark_id, job_id=_job.job_id\n",
    "        ).status\n",
    "    print(f\"Job status is {status}\")\n",
    "    _eval_response = client.eval.jobs.retrieve(\n",
    "        benchmark_id=qna_benchmark_id, job_id=_job.job_id\n",
    "    )\n",
    "\n",
    "    return _eval_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08b987d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_label(score_row):\n",
    "    \"\"\"\n",
    "    Returns the display label for the given `score_row`.\n",
    "    \"\"\"\n",
    "    grades = {'A': 'CORRECT', 'B': 'INCORRECT', 'C': 'NOT_ATTEMPTED'}\n",
    "    score = score_row.get('score', str(score_row))\n",
    "    return grades.get(score,  f'UNKNOWN {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f3c5d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_scores(response):\n",
    "    \"\"\"\n",
    "    Converts the computed scores in a numeric array, where scores `A` are evaluated to 1\n",
    "    and all the others to `0`.\n",
    "    \"\"\"\n",
    "    def category_to_number(category):\n",
    "        if category == 'A':\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    return [category_to_number(score_row['score']) for score_row in response.scores['llm-as-judge::405b-simpleqa'].score_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a375726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_for_paired_samples(scores_a, scores_b, iterations=10_000):\n",
    "    \"\"\"\n",
    "    Performs a permutation test of a given statistic on provided data.\n",
    "    \"\"\"\n",
    "\n",
    "    from scipy.stats import permutation_test\n",
    "\n",
    "\n",
    "    def _statistic(x, y, axis):\n",
    "        return np.mean(x, axis=axis) - np.mean(y, axis=axis)\n",
    "\n",
    "    result = permutation_test(\n",
    "        data=(scores_a, scores_b),\n",
    "        statistic=_statistic,\n",
    "        n_resamples=iterations,\n",
    "        alternative='two-sided',\n",
    "        permutation_type='samples'\n",
    "    )\n",
    "    return float(result.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee78f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_significance(scores_a, scores_b):\n",
    "    mean_score_a = np.mean(scores_a)\n",
    "    mean_score_b = np.mean(scores_b)\n",
    "\n",
    "    p_value = permutation_test_for_paired_samples(scores_a, scores_b)\n",
    "\n",
    "    print(f\" {model_id:<50}: {mean_score_a:>10.4f}\")\n",
    "    print(f\" {'p_value':<50}: {p_value:>10.4f}\")\n",
    "    print()\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(\"p_value<0.05 so this result is statistically significant\")\n",
    "        # Note that the logic below if wrong if the mean scores are equal, but that can't be true if p<1.\n",
    "        higher_model_id = (\n",
    "            FOUNDATION_LLM_MODEL_ID\n",
    "            if mean_score_a >= mean_score_b\n",
    "            else TRAINED_LLM_MODEL_ID\n",
    "        )\n",
    "        print(f\"You can conclude that {higher_model_id} is better on data of this sort\")\n",
    "    else:\n",
    "        import math\n",
    "\n",
    "        print(\"p_value>=0.05 so this result is NOT statistically significant\")\n",
    "        print(\n",
    "            f\"You can conclude that there is not enough data to tell which is better.\"\n",
    "        )\n",
    "        num_samples = len(scores_a)\n",
    "        margin_of_error = 1 / math.sqrt(num_samples)\n",
    "        print(\n",
    "            f\"Note that this data includes {num_samples} questions which typically produces a margin of error of around +/-{margin_of_error:.1%}.\"\n",
    "        )\n",
    "        print(f\"So the two are probably roughly within that margin of error or so.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb84253d",
   "metadata": {},
   "source": [
    "## 4. Creating an evaluation Dataset\n",
    "- Load the Q&A file as a Pandas DataFrame.\n",
    "- Transform the dataset to a schema suitable for LLS evaluations.\n",
    "- Register a new Dataset.\n",
    "- Register a Benchmark using the Dataset and the `llm-as-judge::405b-simpleqa` scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca041b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(QNA_FILE, \"r\") as f:\n",
    "    qnas_df = pd.read_json(f, lines=True)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "145d5514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_query</th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>chat_completion_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why might Parasol Financial include a quiz on the Better Money Habits homepage?</td>\n",
       "      <td>Parasol Financial might include a quiz on the Better Money Habits homepage to tailor the content to the user's specific life stage and interests, thereby making the financial advice more relevant and effective for each individual.</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"Why might Parasol Financial include a quiz on the Better Money Habits homepage?\", \"context\": null}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the main topics covered in the Banking Essentials guide?</td>\n",
       "      <td>The main topics covered in the Banking Essentials guide are an introduction to the financial services industry, the business of banking, working in banking, and working at Parasol Financial.</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"What are the main topics covered in the Banking Essentials guide?\", \"context\": null}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are some reasons a Zelle transfer might be delayed or canceled?</td>\n",
       "      <td>A Zelle transfer might be delayed or canceled due to the need for identity verification, the recipient not enrolling with Zelle, fraud prevention, regulatory compliance, insufficient funds, ineligibility to use Zelle, invalid recipient information, security reasons, exceeding applicable limits, or if the payment cannot be processed.</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"What are some reasons a Zelle transfer might be delayed or canceled?\", \"context\": null}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many business days are required for a Payee to receive and process a request to discontinue a particular e-Bill?</td>\n",
       "      <td>Seven (7) business days.</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"How many business days are required for a Payee to receive and process a request to discontinue a particular e-Bill?\", \"context\": null}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the name of the training program implemented by Wealth Management Specialists?</td>\n",
       "      <td>Elite Growth Practice (EGP)</td>\n",
       "      <td>[{\"role\": \"user\", \"content\": \"What is the name of the training program implemented by Wealth Management Specialists?\", \"context\": null}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            input_query  \\\n",
       "0                                       Why might Parasol Financial include a quiz on the Better Money Habits homepage?   \n",
       "1                                                     What are the main topics covered in the Banking Essentials guide?   \n",
       "2                                                  What are some reasons a Zelle transfer might be delayed or canceled?   \n",
       "3  How many business days are required for a Payee to receive and process a request to discontinue a particular e-Bill?   \n",
       "4                                What is the name of the training program implemented by Wealth Management Specialists?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                  expected_answer  \\\n",
       "0                                                                                                          Parasol Financial might include a quiz on the Better Money Habits homepage to tailor the content to the user's specific life stage and interests, thereby making the financial advice more relevant and effective for each individual.   \n",
       "1                                                                                                                                                  The main topics covered in the Banking Essentials guide are an introduction to the financial services industry, the business of banking, working in banking, and working at Parasol Financial.   \n",
       "2  A Zelle transfer might be delayed or canceled due to the need for identity verification, the recipient not enrolling with Zelle, fraud prevention, regulatory compliance, insufficient funds, ineligibility to use Zelle, invalid recipient information, security reasons, exceeding applicable limits, or if the payment cannot be processed.   \n",
       "3                                                                                                                                                                                                                                                                                                                        Seven (7) business days.   \n",
       "4                                                                                                                                                                                                                                                                                                                     Elite Growth Practice (EGP)   \n",
       "\n",
       "                                                                                                                                                    chat_completion_input  \n",
       "0                                       [{\"role\": \"user\", \"content\": \"Why might Parasol Financial include a quiz on the Better Money Habits homepage?\", \"context\": null}]  \n",
       "1                                                     [{\"role\": \"user\", \"content\": \"What are the main topics covered in the Banking Essentials guide?\", \"context\": null}]  \n",
       "2                                                  [{\"role\": \"user\", \"content\": \"What are some reasons a Zelle transfer might be delayed or canceled?\", \"context\": null}]  \n",
       "3  [{\"role\": \"user\", \"content\": \"How many business days are required for a Payee to receive and process a request to discontinue a particular e-Bill?\", \"context\": null}]  \n",
       "4                                [{\"role\": \"user\", \"content\": \"What is the name of the training program implemented by Wealth Management Specialists?\", \"context\": null}]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_stack.apis.inference import UserMessage\n",
    "import json\n",
    "import random\n",
    "\n",
    "qna_dataset_rows = []\n",
    "\n",
    "chat_completion_input = UserMessage(content=\"\")\n",
    "for i in range(len(qnas_df)):\n",
    "    qna = {}\n",
    "    qna[\"input_query\"] = qnas_df.iloc[i][\"question\"]\n",
    "    qna[\"expected_answer\"] = qnas_df.iloc[i][\"answer\"]\n",
    "\n",
    "    chat_completion_input.content = qna[\"input_query\"]\n",
    "    qna[\"chat_completion_input\"] = json.dumps([chat_completion_input.model_dump()])\n",
    "\n",
    "    qna_dataset_rows.append(qna)\n",
    "\n",
    "random.shuffle(qna_dataset_rows)\n",
    "qna_dataset_df = pd.DataFrame(qna_dataset_rows)\n",
    "qna_dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22fd5734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Registered dataset **test_dataset_2b68a4bc-25b2-11f0-8149-4a70c355aff9**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qna_dataset_id = f\"test_dataset_{uuid.uuid1()}\"\n",
    "_ = client.datasets.register(\n",
    "    purpose=\"eval/messages-answer\",\n",
    "    source={\n",
    "        \"type\": \"rows\",\n",
    "        \"rows\": qna_dataset_rows,\n",
    "    },\n",
    "    dataset_id=qna_dataset_id,\n",
    ")\n",
    "display_markdown(f\"Registered dataset **{qna_dataset_id}**\", raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b669a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Registered benchmark **test_benchmark_2b96f772-25b2-11f0-8149-4a70c355aff9**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qna_benchmark_id = f\"test_benchmark_{uuid.uuid1()}\"\n",
    "client.benchmarks.register(\n",
    "    benchmark_id=qna_benchmark_id,\n",
    "    dataset_id=qna_dataset_id,\n",
    "    scoring_functions=[\"llm-as-judge::405b-simpleqa\"],\n",
    ")\n",
    "display_markdown(f\"Registered benchmark **{qna_benchmark_id}**\", raw=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd43d5",
   "metadata": {},
   "source": [
    "## 5. LLM Eval without RAG\n",
    "- Create an agent configuration without the `knowledge_search` tool.\n",
    "- Run the evaluation function with the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "451b9177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status is completed\n",
      "Evaluation of 50 Q&A workflows completed in 387.938 seconds\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Computed accuracy is 38.0%**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "vanilla_responses = {}\n",
    "_job = _run_eval(use_rag=False)\n",
    "# pprint(_job)\n",
    "_eval_response = _get_eval_reponse(_job)\n",
    "if EVAL_DEBUG == True:\n",
    "    pprint(_eval_response)\n",
    "\n",
    "print(\n",
    "    f\"Evaluation of {MAX_QNA_ROWS} Q&A workflows completed in {time.time() - start:.3f} seconds\"\n",
    ")\n",
    "display_markdown(\n",
    "    f\"**Computed accuracy is {accuracy_from_categorical_count(_eval_response)}%**\",\n",
    "    raw=True,\n",
    ")\n",
    "vanilla_responses[model_id] = _eval_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe7cd9",
   "metadata": {},
   "source": [
    "## 6. LLM Eval with RAG\n",
    "- Create an agent configuration with the `knowledge_search` tool.\n",
    "- Run the evaluation function with the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32b7402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status is completed\n",
      "Evaluation of 50 Q&A workflows completed in 247.808 seconds\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Computed accuracy is 46.0%**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**RAG knowledge search tool used in 32 of (50) agentic calls**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "rag_responses = {}\n",
    "_job = _run_eval(use_rag=True)\n",
    "# pprint(_job)\n",
    "_eval_response = _get_eval_reponse(_job)\n",
    "if EVAL_DEBUG == True:\n",
    "    pprint(_eval_response)\n",
    "\n",
    "print(\n",
    "    f\"Evaluation of {MAX_QNA_ROWS} Q&A workflows completed in {time.time() - start:.3f} seconds\"\n",
    ")\n",
    "display_markdown(\n",
    "    f\"**Computed accuracy is {accuracy_from_categorical_count(_eval_response)}%**\",\n",
    "    raw=True,\n",
    ")\n",
    "rag_responses[model_id] = _eval_response\n",
    "\n",
    "retrieved_contexts = sum(\n",
    "    [1 for r in rag_responses[model_id].generations if \"context\" in r]\n",
    ")\n",
    "display_markdown(\n",
    "    f\"**RAG knowledge search tool used in {retrieved_contexts} of ({MAX_QNA_ROWS}) agentic calls**\",\n",
    "    raw=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5639413-90d6-42ae-add4-6c89da0297e2",
   "metadata": {},
   "source": [
    "## 4. Reporting\n",
    "- Aggregated accuracy.\n",
    "- Individual scores and responses.\n",
    "- Statistical Significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4df0d8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_927e9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_927e9_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_927e9_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_927e9_level0_col2\" class=\"col_heading level0 col2\" >RAG Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_927e9_row0_col0\" class=\"data row0 col0\" >granite32-8b</td>\n",
       "      <td id=\"T_927e9_row0_col1\" class=\"data row0 col1\" >38.000000</td>\n",
       "      <td id=\"T_927e9_row0_col2\" class=\"data row0 col2\" >46.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13468de80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_responses = {}\n",
    "pd_responses['questions'] = [qna_dataset_rows[i]['input_query'] for i in range(MAX_QNA_ROWS)]\n",
    "pd_responses['expected'] = [qna_dataset_rows[i]['expected_answer'] for i in range(MAX_QNA_ROWS)]\n",
    "\n",
    "pd_accuracies = {}\n",
    "df_accuracies = pd.DataFrame.from_dict({\n",
    "    'Model': vanilla_responses.keys(),\n",
    "    'Accuracy': [accuracy_from_categorical_count(vanilla_responses[model_id]) for model_id in vanilla_responses.keys()],\n",
    "    'RAG Accuracy': [accuracy_from_categorical_count(rag_responses[model_id]) for model_id in rag_responses.keys()]})\n",
    "df_accuracies.style.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95b9baa2-4739-426a-b79a-2ff90f44c023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report_data = {}\n",
    "ratings_data = {}\n",
    "responses_data = {}\n",
    "\n",
    "report_data['Question'] = [qna_dataset_rows[i]['input_query'] for i in range(MAX_QNA_ROWS)]\n",
    "ratings_data['Question'] = report_data['Question']\n",
    "responses_data['Question'] = report_data['Question']\n",
    "report_data['Expected Answer'] = [qna_dataset_rows[i]['expected_answer'] for i in range(MAX_QNA_ROWS)]\n",
    "responses_data['Expected Answer'] = report_data['Expected Answer']\n",
    "for model_id in vanilla_responses.keys():\n",
    "    report_data[f'{model_id} Rating'] = [to_label(score_row) for score_row in vanilla_responses[model_id].scores['llm-as-judge::405b-simpleqa'].score_rows]\n",
    "    report_data[f'{model_id} Answer'] = [g['generated_answer'] for g in vanilla_responses[model_id].generations]\n",
    "    report_data[f'{model_id} RAG Rating'] = [to_label(score_row) for score_row in rag_responses[model_id].scores['llm-as-judge::405b-simpleqa'].score_rows]\n",
    "    report_data[f'{model_id} RAG Answer'] = [g['generated_answer'] for g in rag_responses[model_id].generations]\n",
    "    \n",
    "    ratings_data[f'{model_id} Rating'] = report_data[f'{model_id} Rating']\n",
    "    ratings_data[f'{model_id} RAG Rating'] = report_data[f'{model_id} RAG Rating']\n",
    "    responses_data[f'{model_id} Answer'] = report_data[f'{model_id} Answer']\n",
    "    responses_data[f'{model_id} RAG Answer'] = report_data[f'{model_id} RAG Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "272729b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Response Comparison**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Question</th>\n",
       "      <th>Expected Answer</th>\n",
       "      <th>granite32-8b Rating</th>\n",
       "      <th>granite32-8b Answer</th>\n",
       "      <th>granite32-8b RAG Rating</th>\n",
       "      <th>granite32-8b RAG Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Why might Parasol Financial include a quiz on the Better Money Habits homepage?</td>\n",
       "      <td>Parasol Financial might include a quiz on the Better Money Habits homepage to tailor the content to the user's specific life stage and interests, thereby making the financial advice more relevant and effective for each individual.</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>Parasol Financial might include a quiz on the Better Money Habits homepage for several reasons:\\n\\n1. **Engagement**: Quizzes are an engaging way to capture and maintain user interest. They provide an interactive experience that can keep visitors on the site longer.\\n\\n2. **Education**: The quiz can serve as an educational tool, helping users understand their current financial habits and knowledge. This can be particularly useful in a context like Better Money Habits, which aims to improve financial literacy.\\n\\n3. **Personalization**: Based on the quiz results, Parasol Financial can offer personalized financial advice or resources. This tailored approach can make users feel the content is more relevant to their specific needs.\\n\\n4. **Data Collection**: The quiz can also serve as a method to collect data about users' financial behaviors and attitudes. This data can be valuable for research, understanding their audience better, and potentially for marketing purposes.\\n\\n5. **Lead Generation**: By offering valuable insights at the end of the quiz, Parasol Financial can encourage users to provide their contact information, thereby generating leads for their financial services.\\n\\n6. **SEO Benefits**: Quizzes can increase the time users spend on a page, which can positively impact search engine rankings. They also often encourage social sharing, which can drive more traffic to the site.\\n\\nRemember, the specific reasons would depend on Parasol Financial's overall strategy and goals for the Better Money Habits platform.</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>To provide users with a personalized financial assessment, Parasol Financial might include a quiz on the Better Money Habits homepage. This quiz could help identify users' financial strengths and weaknesses, offering tailored advice and resources based on their responses. It's a way to engage users and provide them with actionable insights to improve their financial literacy and habits.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What are the main topics covered in the Banking Essentials guide?</td>\n",
       "      <td>The main topics covered in the Banking Essentials guide are an introduction to the financial services industry, the business of banking, working in banking, and working at Parasol Financial.</td>\n",
       "      <td>NOT_ATTEMPTED</td>\n",
       "      <td>The Banking Essentials guide typically covers a broad range of topics that provide a foundational understanding of the banking industry. Here are some of the main topics you might find:\\n\\n1. **Introduction to Banking**: This section provides an overview of what banking is, its history, and its role in the economy.\\n\\n2. **Types of Banks**: It explains the different types of banks, such as commercial banks, investment banks, central banks, and retail banks, and their specific functions.\\n\\n3. **Banking Services**: This part delves into the services offered by banks, including deposit accounts, loans, credit cards, wealth management, and more.\\n\\n4. **Banking Operations**: It covers the day-to-day operations of a bank, including transaction processing, risk management, and compliance.\\n\\n5. **Financial Instruments**: This topic explains various financial instruments like securities, bonds, stocks, and derivatives, which banks deal with.\\n\\n6. **Monetary Policy and Central Banking**: It discusses the role of central banks in managing a country's money supply, setting interest rates, and maintaining financial stability.\\n\\n7. **Regulation and Compliance**: This section covers the laws, regulations, and standards that banks must adhere to, including anti-money laundering (AML) and know-your-customer (KYC) procedures.\\n\\n8. **Technology in Banking**: It explores how technology, such as online banking, mobile banking, blockchain, and AI, is transforming the banking sector.\\n\\n9. **Banking Careers**: This part provides insights into various roles within the banking industry, required skills, and career progression paths.\\n\\n10. **Global Banking**: It discusses international banking, cross-border transactions, and the impact of global economic trends on the banking sector.\\n\\nRemember, the specific topics can vary depending on the guide's author or publisher. Always refer to the specific guide for the most accurate information.</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>The main topics covered in the Banking Essentials guide include:\\n\\n1. Introduction to the financial services industry, including banking, investing, insurance, and tax and accounting.\\n2. The business of banking, which includes various roles such as client management, financial advisory, investment banking, sales and trading, accounting, credit, wealth management, and client services.\\n3. Technology and operations roles that support customer and client needs, including data management, operations, web design, cyber security, software engineering, and help desk.\\n4. Business support services like human resources, research and development, program management, strategy and innovation, marketing, and corporate social responsibility.\\n5. Skills needed to succeed in the financial services industry, such as being detail-oriented, ethical, a problem solver, having good customer interaction skills, and being a rule follower.\\n6. Information about working at Parasol Financial, including job previews for roles in banking, markets, and finance, technology and operations, and business support services.\\n7. The concept of corporate culture and its importance in a banking environment, emphasizing the need for a culture of ethics and responsibility.\\n8. Resources for further learning, including community college courses and certificates in banking and finance topics.\\n9. An introduction to Parasol Financial's training and professional development organization, dedicated to the growth and success of local communities and teammates.\\n10. Information about Parasol Financial's commitment to financial health through their Better Money Habits initiative, a website designed to help manage personal finances and make better financial decisions.\\n11. Details about Parasol Financial's benefits package, which includes tuition assistance, automatic enrollment in a 401k plan, a benefits education and planning center, financial wellness tracker, and more.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What are some reasons a Zelle transfer might be delayed or canceled?</td>\n",
       "      <td>A Zelle transfer might be delayed or canceled due to the need for identity verification, the recipient not enrolling with Zelle, fraud prevention, regulatory compliance, insufficient funds, ineligibility to use Zelle, invalid recipient information, security reasons, exceeding applicable limits, or if the payment cannot be processed.</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>Zelle, a popular digital payment service, can sometimes experience delays or cancellations in transfers for several reasons:\\n\\n1. **Incorrect Recipient Information**: If the recipient's account number, routing number, or email address or U.S. mobile number is entered incorrectly, the transfer may be delayed or canceled.\\n\\n2. **Insufficient Funds**: If the sender doesn't have enough money in their account to cover the transfer, the transaction may be declined.\\n\\n3. **Bank or Financial Institution Issues**: Sometimes, delays can occur due to technical issues or maintenance at the sender's or recipient's bank.\\n\\n4. **Zelle Service Limitations**: Zelle has certain limits on the amount and frequency of transactions. If these limits are exceeded, the transfer might be delayed or canceled.\\n\\n5. **Fraud Detection**: Zelle has systems in place to detect and prevent fraudulent activities. If a transaction is flagged as potentially fraudulent, it may be delayed or canceled until further verification.\\n\\n6. **Network Outages or Technical Glitches**: Like any digital service, Zelle can experience outages or technical glitches that might cause delays or cancellations.\\n\\n7. **Recipient's Bank Policies**: Some banks may have their own policies or procedures that can cause delays in receiving Zelle payments.\\n\\n8. **Time of Transfer**: Transfers made on weekends or holidays might experience delays as banks may have reduced operating hours or staff.\\n\\n9. **Account Verification**: If the recipient's account is new or hasn't been verified yet, the transfer might be delayed or require additional steps to complete.\\n\\n10. **Zelle Suspension or Cancellation**: If a user's account is suspended or canceled by Zelle, any pending transactions will likely be affected.\\n\\nIf you're experiencing a delay or cancellation, it's best to contact Zelle customer service for specific details about your situation.</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>Zelle transfers might be delayed or canceled for several reasons:\\n\\n1. The recipient does not enroll in the Zelle service within 14 days of receiving the transfer notification.\\n2. The recipient's account number, email, or mobile number is invalid.\\n3. The recipient has deleted their Zelle account.\\n4. The transfer is blocked to prevent fraud or comply with regulatory requirements.\\n5. The sender's payment account is closed or does not have sufficient funds.\\n6. The sender is ineligible to use Zelle.\\n7. The transfer is scheduled and then canceled by the sender.\\n8. Technical issues or delays in processing the transfer.\\n\\nIt's important to note that Zelle does not offer purchase protection for authorized payments made through the service.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>How many business days are required for a Payee to receive and process a request to discontinue a particular e-Bill?</td>\n",
       "      <td>Seven (7) business days.</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>The number of business days required for a Payee to receive and process a request to discontinue a particular e-Bill can vary depending on the specific policies of the Payee. Typically, it can range from 1 to 5 business days. However, it's best to check with the specific Payee for their exact processing time. Some Payees may provide an immediate response, while others might require more time to update their systems.</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>Based on the provided information, there's no specific timeframe mentioned for a Payee to receive and process a request to discontinue a particular e-Bill. However, generally, once you cancel an e-Bill through the Bill Pay service, it should be discontinued immediately. The Payee should then stop sending e-Bills, but the exact processing time can vary depending on the Payee's internal procedures. It's always a good idea to confirm the cancellation with the Payee directly if you're concerned about the timing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What is the name of the training program implemented by Wealth Management Specialists?</td>\n",
       "      <td>Elite Growth Practice (EGP)</td>\n",
       "      <td>NOT_ATTEMPTED</td>\n",
       "      <td>The specific training program implemented by Wealth Management Specialists can vary depending on the company or individual specialist. However, a well-known and widely recognized training program in the wealth management industry is the Chartered Financial Analyst (CFA) program. This is a professional designation offered by the CFA Institute.\\n\\nOther notable training programs include:\\n\\n1. Certified Financial Planner (CFP) - offered by the Certified Financial Planner Board of Standards, Inc.\\n2. Financial Risk Manager (FRM) - offered by the Global Association of Risk Professionals (GARP)\\n3. Chartered Investment Management Analyst (CIMA) - offered by the CAIA Association\\n\\nThese programs provide comprehensive training in various aspects of wealth management, including investment management, financial planning, and risk management. \\n\\nPlease note that not all wealth management specialists may undergo these specific programs, as there are many paths to becoming a wealth management professional. Some may have degrees in finance, economics, or related fields, and gain experience through on-the-job training or other professional development opportunities.</td>\n",
       "      <td>NOT_ATTEMPTED</td>\n",
       "      <td>Based on the provided information, there is no specific training program named by Wealth Management Specialists. The document mentions various roles such as Associates, Fraud Client Services Representatives, Credit Assistance Specialists, Home Services Associates, and Trainees, but no specific training program for Wealth Management Specialists is explicitly mentioned.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "display_markdown(\"**Response Comparison**\", raw=True)\n",
    "report_df = pd.DataFrame.from_dict(report_data)\n",
    "HTML(report_df.head().to_html(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5409d599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Statistical Significance (vanilla Vs RAG generations)**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " granite32-8b                                      :     0.3800\n",
      " p_value                                           :     0.4806\n",
      "\n",
      "p_value>=0.05 so this result is NOT statistically significant\n",
      "You can conclude that there is not enough data to tell which is better.\n",
      "Note that this data includes 50 questions which typically produces a margin of error of around +/-14.1%.\n",
      "So the two are probably roughly within that margin of error or so.\n"
     ]
    }
   ],
   "source": [
    "display_markdown(\"**Statistical Significance (vanilla Vs RAG generations)**\", raw= True)\n",
    "print_stats_significance(numeric_scores(vanilla_responses[model_id]), numeric_scores(rag_responses[model_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6937a3-3efa-4b66-aaf0-85d96b6d43db",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "This tutorial demonstrates how to evaluate an agentic workflow, without and without RAG tool, using the Llama Stack reference implementation.\n",
    "We do so by initializing an agent, with optional access to the RAG tool, then invoking the agent evaluation against a predefined reference of sample Q&A. \n",
    "Please check out our [complementary tutorial](Level3_agentic_RAG.ipynb) for an agentic RAG example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
